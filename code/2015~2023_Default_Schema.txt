from pyspark.sql import SparkSession
from pyspark.sql import functions as F

#SparkSession 초기화
spark = SparkSession.builder.appName("FireAnalysis").getOrCreate()

#파일 경로 설정(2015 ~ 2022년)
base_path = "dbfs:/FileStore/"
file_paths = [base_path + f"{year}_fire_O_utf.csv" for year in range(2015, 2023)]  #2015년부터 2022년까지 파일 리스트

#각 파일에 대한 컬럼 정보와 통계 출력
for file_path in file_paths:
    데이터 로드
    df = spark.read.option("header", "true").csv(file_path)
    
    #데이터의 기본 정보 출력
    print(f"[{file_path} 데이터의 기본 정보]")
    df.printSchema()  #스키마 정보 확인
    
    #기본 통계 분석 (수치형 데이터)
    print(f"\n[{file_path} 기본 통계량]")
    df.describe().show()

    print("=" * 80)