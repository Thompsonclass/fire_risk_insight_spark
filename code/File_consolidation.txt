from pyspark.sql import SparkSession
from pyspark.sql import functions as F

#SparkSession 초기화
spark = SparkSession.builder.appName("FireAnalysis").getOrCreate()

#파일 경로 설정(2015 ~ 2022년)
base_path = "dbfs:/FileStore/"
file_paths = [base_path + f"{year}_fire_O_utf.csv" for year in range(2015, 2023)]  #2015년부터 2022년까지 파일 리스트

#필요한 컬럼 순서 설정
required_columns = [
    "일시",
    "시도",
    "시·군·구",
    "화재유형",
    "발화열원대분류",
    "발화열원소분류",
    "발화요인대분류",
    "발화요인소분류",
    "최초착화물대분류",
    "최초착화물소분류",
    "인명피해(명)소계",
    "재산피해소계",
    "장소대분류",
    "장소중분류",
    "장소소분류"
]

#데이터 로드 및 통합
merged_df = None

for file_path in file_paths:
    #파일 로드
    df = spark.read.option("header", "true").csv(file_path)
    
    #필요한 컬럼만 선택하고 순서 맞추기
    df = df.select([col for col in required_columns if col in df.columns])
    
    #통합
    if merged_df is None:
        merged_df = df
    else:
        merged_df = merged_df.union(df)

output_path = "/FileStore/merged_sorted_fire_data.csv"
merged_df.coalesce(1).write.option("header", "true").mode("overwrite").csv(output_path)

print(f"통합된 데이터는 {output_path}에 저장되었습니다.")
